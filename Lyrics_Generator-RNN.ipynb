{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4d767f6",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f8ff; padding: 15px; border-radius: 5px; border-left: 5px solid #4169e1;\">\n",
    "<h2 style=\"color: #4169e1;\">Project Overview</h2>\n",
    "<p style=\"color: #333;\">In this project, I aim to develop a model capable of generating song lyrics using Recurrent Neural Networks (RNNs). The objective is to explore the creative potential of RNNs in text generation, specifically within the context of songwriting. Building a lyrics generator has long been on my list of projects, and I am excited to finally bring this idea to life by leveraging deep learning techniques to produce original and creative text.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f209b2",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e6ffe6; padding: 10px; border-radius: 5px; border-left: 5px solid #228B22;\">\n",
    "<h2 style=\"color: #228B22;\">Importing Libraries</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "285996fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ansar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db1dd97",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73002e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>track_popularity</th>\n",
       "      <th>track_album_id</th>\n",
       "      <th>track_album_name</th>\n",
       "      <th>track_album_release_date</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0017A6SJgTbfQVU2EtsPNo</td>\n",
       "      <td>Pangarap</td>\n",
       "      <td>Barbie's Cradle</td>\n",
       "      <td>Minsan pa Nang ako'y napalingon Hindi ko alam ...</td>\n",
       "      <td>41</td>\n",
       "      <td>1srJQ0njEQgd8w4XSqI4JQ</td>\n",
       "      <td>Trip</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>Pinoy Classic Rock</td>\n",
       "      <td>37i9dQZF1DWYDQ8wBxd7xt</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.068</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.27900</td>\n",
       "      <td>0.01170</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.566</td>\n",
       "      <td>97.091</td>\n",
       "      <td>235440</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004s3t0ONYlzxII9PLgU6z</td>\n",
       "      <td>I Feel Alive</td>\n",
       "      <td>Steady Rollin</td>\n",
       "      <td>The trees, are singing in the wind The sky blu...</td>\n",
       "      <td>28</td>\n",
       "      <td>3z04Lb9Dsilqw68SHt6jLB</td>\n",
       "      <td>Love &amp; Loss</td>\n",
       "      <td>2017-11-21</td>\n",
       "      <td>Hard Rock Workout</td>\n",
       "      <td>3YouF0u7waJnolytf9JCXf</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.739</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.01170</td>\n",
       "      <td>0.00994</td>\n",
       "      <td>0.3470</td>\n",
       "      <td>0.404</td>\n",
       "      <td>135.225</td>\n",
       "      <td>373512</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00chLpzhgVjxs1zKC9UScL</td>\n",
       "      <td>Poison</td>\n",
       "      <td>Bell Biv DeVoe</td>\n",
       "      <td>NA Yeah, Spyderman and Freeze in full effect U...</td>\n",
       "      <td>0</td>\n",
       "      <td>6oZ6brjB8x3GoeSYdwJdPc</td>\n",
       "      <td>Gold</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>Back in the day - R&amp;B, New Jack Swing, Swingbe...</td>\n",
       "      <td>3a9y4eeCJRmG9p4YKfqYIx</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.504</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.00432</td>\n",
       "      <td>0.00723</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>0.650</td>\n",
       "      <td>111.904</td>\n",
       "      <td>262467</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00cqd6ZsSkLZqGMlQCR0Zo</td>\n",
       "      <td>Baby It's Cold Outside (feat. Christina Aguilera)</td>\n",
       "      <td>CeeLo Green</td>\n",
       "      <td>I really can't stay Baby it's cold outside I'v...</td>\n",
       "      <td>41</td>\n",
       "      <td>3ssspRe42CXkhPxdc12xcp</td>\n",
       "      <td>CeeLo's Magic Moment</td>\n",
       "      <td>2012-10-29</td>\n",
       "      <td>Christmas Soul</td>\n",
       "      <td>6FZYc2BvF7tColxO8PBShV</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.819</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.68900</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.405</td>\n",
       "      <td>118.593</td>\n",
       "      <td>243067</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00emjlCv9azBN0fzuuyLqy</td>\n",
       "      <td>Dumb Litty</td>\n",
       "      <td>KARD</td>\n",
       "      <td>Get up out of my business You don't keep me fr...</td>\n",
       "      <td>65</td>\n",
       "      <td>7h5X3xhh3peIK9Y0qI5hbK</td>\n",
       "      <td>KARD 2nd Digital Single ‘Dumb Litty’</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>K-Party Dance Mix</td>\n",
       "      <td>37i9dQZF1DX4RDXswvP6Mj</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.993</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.240</td>\n",
       "      <td>130.018</td>\n",
       "      <td>193160</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id                                         track_name  \\\n",
       "0  0017A6SJgTbfQVU2EtsPNo                                           Pangarap   \n",
       "1  004s3t0ONYlzxII9PLgU6z                                       I Feel Alive   \n",
       "2  00chLpzhgVjxs1zKC9UScL                                             Poison   \n",
       "3  00cqd6ZsSkLZqGMlQCR0Zo  Baby It's Cold Outside (feat. Christina Aguilera)   \n",
       "4  00emjlCv9azBN0fzuuyLqy                                         Dumb Litty   \n",
       "\n",
       "      track_artist                                             lyrics  \\\n",
       "0  Barbie's Cradle  Minsan pa Nang ako'y napalingon Hindi ko alam ...   \n",
       "1    Steady Rollin  The trees, are singing in the wind The sky blu...   \n",
       "2   Bell Biv DeVoe  NA Yeah, Spyderman and Freeze in full effect U...   \n",
       "3      CeeLo Green  I really can't stay Baby it's cold outside I'v...   \n",
       "4             KARD  Get up out of my business You don't keep me fr...   \n",
       "\n",
       "   track_popularity          track_album_id  \\\n",
       "0                41  1srJQ0njEQgd8w4XSqI4JQ   \n",
       "1                28  3z04Lb9Dsilqw68SHt6jLB   \n",
       "2                 0  6oZ6brjB8x3GoeSYdwJdPc   \n",
       "3                41  3ssspRe42CXkhPxdc12xcp   \n",
       "4                65  7h5X3xhh3peIK9Y0qI5hbK   \n",
       "\n",
       "                       track_album_name track_album_release_date  \\\n",
       "0                                  Trip               2001-01-01   \n",
       "1                           Love & Loss               2017-11-21   \n",
       "2                                  Gold               2005-01-01   \n",
       "3                  CeeLo's Magic Moment               2012-10-29   \n",
       "4  KARD 2nd Digital Single ‘Dumb Litty’               2019-09-22   \n",
       "\n",
       "                                       playlist_name             playlist_id  \\\n",
       "0                                 Pinoy Classic Rock  37i9dQZF1DWYDQ8wBxd7xt   \n",
       "1                                  Hard Rock Workout  3YouF0u7waJnolytf9JCXf   \n",
       "2  Back in the day - R&B, New Jack Swing, Swingbe...  3a9y4eeCJRmG9p4YKfqYIx   \n",
       "3                                     Christmas Soul  6FZYc2BvF7tColxO8PBShV   \n",
       "4                                  K-Party Dance Mix  37i9dQZF1DX4RDXswvP6Mj   \n",
       "\n",
       "   ... loudness mode  speechiness  acousticness  instrumentalness  liveness  \\\n",
       "0  ...  -10.068    1       0.0236       0.27900           0.01170    0.0887   \n",
       "1  ...   -4.739    1       0.0442       0.01170           0.00994    0.3470   \n",
       "2  ...   -7.504    0       0.2160       0.00432           0.00723    0.4890   \n",
       "3  ...   -5.819    0       0.0341       0.68900           0.00000    0.0664   \n",
       "4  ...   -1.993    1       0.0409       0.03700           0.00000    0.1380   \n",
       "\n",
       "   valence    tempo  duration_ms  language  \n",
       "0    0.566   97.091       235440        tl  \n",
       "1    0.404  135.225       373512        en  \n",
       "2    0.650  111.904       262467        en  \n",
       "3    0.405  118.593       243067        en  \n",
       "4    0.240  130.018       193160        en  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"spotify_songs.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035c5bd6",
   "metadata": {},
   "source": [
    "### To keep the model simple I am going to drop unneccesary columns. I will use track_name , trac_artist and lyrics columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e793643",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"track_name\", \"track_artist\", \"lyrics\"]].rename(\n",
    "    columns={\"track_name\": \"Song_Title\", \"track_artist\": \"Artist\", \"lyrics\": \"Lyrics\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0c8e7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pangarap</td>\n",
       "      <td>Barbie's Cradle</td>\n",
       "      <td>Minsan pa Nang ako'y napalingon Hindi ko alam ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I Feel Alive</td>\n",
       "      <td>Steady Rollin</td>\n",
       "      <td>The trees, are singing in the wind The sky blu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poison</td>\n",
       "      <td>Bell Biv DeVoe</td>\n",
       "      <td>NA Yeah, Spyderman and Freeze in full effect U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baby It's Cold Outside (feat. Christina Aguilera)</td>\n",
       "      <td>CeeLo Green</td>\n",
       "      <td>I really can't stay Baby it's cold outside I'v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dumb Litty</td>\n",
       "      <td>KARD</td>\n",
       "      <td>Get up out of my business You don't keep me fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Song_Title           Artist  \\\n",
       "0                                           Pangarap  Barbie's Cradle   \n",
       "1                                       I Feel Alive    Steady Rollin   \n",
       "2                                             Poison   Bell Biv DeVoe   \n",
       "3  Baby It's Cold Outside (feat. Christina Aguilera)      CeeLo Green   \n",
       "4                                         Dumb Litty             KARD   \n",
       "\n",
       "                                              Lyrics  \n",
       "0  Minsan pa Nang ako'y napalingon Hindi ko alam ...  \n",
       "1  The trees, are singing in the wind The sky blu...  \n",
       "2  NA Yeah, Spyderman and Freeze in full effect U...  \n",
       "3  I really can't stay Baby it's cold outside I'v...  \n",
       "4  Get up out of my business You don't keep me fr...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4a35c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Song_Title      0\n",
       "Artist          0\n",
       "Lyrics        260\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96d8247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing values with empty string\n",
    "data[\"Lyrics\"] = data[\"Lyrics\"].fillna(\"\")\n",
    "data = data[data[\"Lyrics\"].str.strip() != \"\"]\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9161de65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Song_Title    0\n",
       "Artist        0\n",
       "Lyrics        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d966e7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artists in the data:\n",
      " Artist\n",
      "Queen                 123\n",
      "Don Omar               74\n",
      "David Guetta           73\n",
      "Drake                  65\n",
      "Guns N' Roses          63\n",
      "                     ... \n",
      "Christina Grimmie       1\n",
      "Luke Bryan              1\n",
      "Magic City Hippies      1\n",
      "Rocco Hunt              1\n",
      "Steady Rollin           1\n",
      "Name: count, Length: 5946, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print the artists in the data\n",
    "print(\"Artists in the data:\\n\",data.Artist.value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05ddb33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18194, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb83737",
   "metadata": {},
   "source": [
    "### Extracting more information on the songs such as:\n",
    "\n",
    "* Number of characters\n",
    "* Number of words\n",
    "* Number of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9c3b0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No_of_Characters</th>\n",
       "      <th>No_of_Words</th>\n",
       "      <th>No_of_Lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18194.000000</td>\n",
       "      <td>18194.000000</td>\n",
       "      <td>18194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2138.102067</td>\n",
       "      <td>510.558646</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1713.122517</td>\n",
       "      <td>428.185625</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1164.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1693.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2572.000000</td>\n",
       "      <td>617.750000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27698.000000</td>\n",
       "      <td>6748.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       No_of_Characters   No_of_Words  No_of_Lines\n",
       "count      18194.000000  18194.000000      18194.0\n",
       "mean        2138.102067    510.558646          1.0\n",
       "std         1713.122517    428.185625          0.0\n",
       "min            4.000000      1.000000          1.0\n",
       "25%         1164.000000    269.000000          1.0\n",
       "50%         1693.000000    400.000000          1.0\n",
       "75%         2572.000000    617.750000          1.0\n",
       "max        27698.000000   6748.000000          1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding a column of numbers of Characters,words and sentences in each msg\n",
    "data[\"No_of_Characters\"] = data[\"Lyrics\"].apply(len)\n",
    "data[\"No_of_Words\"]=data.apply(lambda row: nltk.word_tokenize(row[\"Lyrics\"]), axis=1).apply(len)\n",
    "data[\"No_of_Lines\"] = data[\"Lyrics\"].str.split('\\n').apply(len)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6b4ea0",
   "metadata": {},
   "source": [
    "### Removing very short and very long lyrics (e.g., less than 20 words or more than 2000 words).\n",
    "#### Removing duplicates and empty lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edce29be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove very short or very long lyrics\n",
    "data = data[(data['Lyrics'].str.split().apply(len) > 20) & (data['Lyrics'].str.split().apply(len) < 2000)]\n",
    "data = data.drop_duplicates(subset=['Lyrics'])\n",
    "data = data[data['Lyrics'].str.strip() != '']\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf239bb",
   "metadata": {},
   "source": [
    "### Data Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8147735",
   "metadata": {},
   "outputs": [],
   "source": [
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(data['Lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bea7a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a reasonable max sequence length\n",
    "import random\n",
    "\n",
    "MAX_SEQ_LEN = 40\n",
    "\n",
    "sequences = []\n",
    "for lyric in data['Lyrics']:\n",
    "    token_list = tokenizer.texts_to_sequences([lyric])[0]\n",
    "    n_grams = [token_list[:i+1] for i in range(1, min(len(token_list), MAX_SEQ_LEN))]\n",
    "    if len(n_grams) > 10:\n",
    "        n_grams = random.sample(n_grams, 10)\n",
    "    sequences.extend(n_grams)\n",
    "\n",
    "sequences = pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='pre')\n",
    "X, y = sequences[:,:-1], sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "600b23d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(tokenizer.word_index)+1, 50, input_length=MAX_SEQ_LEN-1))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(len(tokenizer.word_index)+1, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28af33f6",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b0ee485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 567ms/step - accuracy: 0.0308 - loss: 8.0830 - val_accuracy: 0.0362 - val_loss: 7.0879\n",
      "Epoch 2/10\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m650s\u001b[0m 587ms/step - accuracy: 0.0451 - loss: 6.6547 - val_accuracy: 0.0594 - val_loss: 6.8563\n",
      "Epoch 3/10\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m665s\u001b[0m 600ms/step - accuracy: 0.0661 - loss: 6.2508 - val_accuracy: 0.0711 - val_loss: 6.7750\n",
      "Epoch 4/10\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m662s\u001b[0m 597ms/step - accuracy: 0.0840 - loss: 6.0020 - val_accuracy: 0.0809 - val_loss: 6.7352\n",
      "Epoch 5/10\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 593ms/step - accuracy: 0.0982 - loss: 5.7937 - val_accuracy: 0.0895 - val_loss: 6.7444\n",
      "Epoch 6/10\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m674s\u001b[0m 608ms/step - accuracy: 0.1091 - loss: 5.6069 - val_accuracy: 0.0941 - val_loss: 6.7556\n",
      "Epoch 7/10\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m717s\u001b[0m 647ms/step - accuracy: 0.1188 - loss: 5.4437 - val_accuracy: 0.0962 - val_loss: 6.7862\n",
      "Epoch 8/10\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m588s\u001b[0m 531ms/step - accuracy: 0.1287 - loss: 5.2817 - val_accuracy: 0.0998 - val_loss: 6.8172\n",
      "Epoch 9/10\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m692s\u001b[0m 625ms/step - accuracy: 0.1387 - loss: 5.1421 - val_accuracy: 0.1028 - val_loss: 6.8746\n",
      "Epoch 10/10\n",
      "\u001b[1m1108/1108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m604s\u001b[0m 545ms/step - accuracy: 0.1489 - loss: 4.9878 - val_accuracy: 0.1037 - val_loss: 6.9126\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X, y, epochs=10, validation_split=0.1, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b0bbb2",
   "metadata": {},
   "source": [
    "### Lyrics generation Funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ec9cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_lyrics(seed_text, next_words=50, max_seq_len=50):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_seq_len-1, padding='pre')\n",
    "        predicted = model.predict(token_list, verbose=0)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == np.argmax(predicted):\n",
    "                output_word = word\n",
    "                break\n",
    "        if output_word == \"\":\n",
    "            break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dd0d0e",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0986ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save model and tokenizer for deployment\n",
    "model.save('lyrics_model.h5')\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
